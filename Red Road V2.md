Here is your refined product specification. I have synthesized our entire discussionâ€”replacing the rigid tables with conversational AI, the complex calendar with the "Daily 3" menu, and the vague thoughts process with the "Incubator."

This is no longer just a "To-Do List"; it is aÂ **Commitment Engine**.

---

# Product Concept: The "Commitment Filter"

**Core Philosophy:**Â Most ideas are noise. Only ideas that survive a "stress test" deserve to be goals. The app focuses onÂ **verifying willingness**Â before tracking execution.

## 1. The Entry Point (The Classifier)

User Input: Voice or Text (e.g., "I want to make a million dollars" or "I feel like a failure").

Agent Logic: Instantly classifies the input into two buckets:

1. **Actionable Intent:**Â Triggers the [Gatekeeper Process].
    
2. **Reflective Thought:**Â Triggers the [Incubator Process].
    

---

## 2. The Gatekeeper (Formerly "Review Phase")

_Instead of a static form, the Agent acts as a gentle skeptic._

### The Conversational Stress Test

The Agent uses user context (Past Patterns, Current Load) to generate 3-5 punchy, realistic questions. It does not show a score to the user; it calculates it in the background.

- **Goal:**Â AssessÂ **Difficulty Tolerance**Â &Â **Intrinsic Drive**.
    
- **The "Context-Aware" logic:**
    
    - _If User is busy:_Â Ask about trade-offs ("What current project will you drop to do this?").
        
    - _If User has failed before:_Â Ask about specific pain points ("You quit guitar because of finger pain. This requires calluses too. Ready for that?").
        

### The Decision Logic (Hidden Backend)

- **High Score (Go):**Â Proceed toÂ **Test Phase**.
    
- **Low Score (No-Go):**Â The Agent says,Â _"This seems like a 'Nice to Have' rather than a 'Must Do' right now. Letâ€™s put it in the Incubator for later."_Â (Soft rejection).
    

---

## 3. The Proving Ground (Formerly "Test Phase")

_Verifying willingness through Action, not promises._

### The MVP Generator

The Agent breaks the goal down into aÂ **"Proof of Work"**â€”a micro-task that requires tangible output.

- **Rule:**Â No passive consumption (e.g., "Watch video"). Only active creation.
    
- **Examples:**
    
    - _Goal:_Â "Learn Coding."Â $\rightarrow$Â _MVP:_Â "Write an HTML file that displays a red box."
        
    - _Goal:_Â "Write a Book."Â $\rightarrow$Â _MVP:_Â "Write a 300-word outline of the villain."
        

### The "Feynman" Verification

When the user clicks "Done," the Agent asks for a 1-sentence synthesis:Â _"Explain the core concept you just learned to a 5-year-old."_Â This ensures the user didn't just cheat the system.

---

## 4. The Action Engine (Formerly "Action Phase")

_Replacing "Calendar Management" with "Energy Management."_

### The "Daily 3" Menu (Scheduling)

Every morning, the Agent serves a curated menu based on the user's energy and available time slots. It prevents burnout by enforcing variety.

1. **The Anchor (High Energy):**Â The deep work task. (e.g., "Code the login feature").
    
2. **The Filler (Medium Energy):**Â Maintenance work. (e.g., "Read 10 pages").
    
3. **The Quick Win (Low Energy):**Â Momentum starter. (e.g., "Reply to 1 email").
    

### The Context Trigger

Instead of strict times (2:00 PM), the Agent usesÂ **State-Based Triggers**:

- _User:_Â "I have 15 mins."Â $\rightarrow$Â _Agent:_Â "Do theÂ **Quick Win**Â task."
    
- _User:_Â "I'm tired."Â $\rightarrow$Â _Agent:_Â "Skip the Anchor. Just do theÂ **Filler**Â task to keep the streak."
    

### The Feedback Loop (Data Collection)

- **Micro-Tags:**Â After an Anchor task, show 3 buttons: ðŸŸ¢ (Easy), ðŸŸ¡ (Okay), ðŸ”´ (Hard).
    
- **Dynamic Difficulty Adjustment:**
    
    - _If "Hard" 3x in a row:_Â Agent suggests breaking the task down further.
        
    - _If "Easy" 3x in a row:_Â Agent suggests increasing the challenge to maintain flow.
        

---

## 5. The Incubator (Formerly "Thoughts Process")

_Handling non-actionable thoughts without judgment._

### The Quarantine Protocol

- **Subjective Thoughts:**Â (e.g., "I'm stupid.")
    
    - **Action:**Â Record as "Belief Tag," not Fact.
        
    - **Response:**Â Socratic Mirroring.Â _"I've logged that you feel stuck. What specific evidence makes you feel that way today?"_
        
- **Factual Errors:**Â (e.g., "I will sleep 2 hours.")
    
    - **Action:**Â Gentle correction with data.Â _"Data shows productivity drops after 18h awake. Shall we set a 'Crash Limit'?"_
        

### Context Mining

The Agent periodically reviews the Incubator:

- _"Youâ€™ve had 'Learn Pottery' in the incubator for 6 months. You mentioned you're bored on weekendsâ€”is it time to move this to the Review Phase?"_
    

---

## Technical Data Model (JSON Structure)

To build this, your database objects should look like this:

JSON

```
{
  "item_id": "102",
  "type": "ACTION_MVP", // or THOUGHT_VENT
  "content": "Learn Python",
  "status": {
    "state": "ACTIVE",
    "difficulty_score": 75, // 0-100 Dynamic Score
    "energy_tag": "HIGH_FOCUS"
  },
  "proof_of_work": {
    "required_output": "Print 'Hello World' in terminal",
    "verification_method": "FEYNMAN_TEST"
  },
  "feedback_log": [
    {"date": "2023-10-01", "mood": "TIRED", "effort": "HARD"}
  ]
}
```

### Next Immediate Step

This specification is now solid. The biggest risk is theÂ **Prompt Engineering**â€”if the Agent's "Review Questions" are boring, the app fails.

**Would you like me to write the final "Master System Prompt" that controls the Gatekeeper (Review Phase)?**